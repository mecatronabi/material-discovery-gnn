{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5eb428-1381-4c62-8195-475af2d07d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Instalaci√≥n autom√°tica de paquetes requeridos\n",
    "# Correr esta celda si cambias de entorno, compu o al compartir tu notebook\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install \\\n",
    "    torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu \\\n",
    "    torch-geometric \\\n",
    "    matminer \\\n",
    "    pymatgen \\\n",
    "    pandas \\\n",
    "    matplotlib \\\n",
    "    scikit-learn \\\n",
    "    jupyterlab \\\n",
    "    ipykernel \\\n",
    "    numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4928586c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 132752\n",
      "Procesando muestra 0...\n",
      "Procesando muestra 1...\n",
      "Procesando muestra 2...\n",
      "Procesando muestra 3...\n",
      "Procesando muestra 4...\n",
      "Procesando muestra 5...\n",
      "Procesando muestra 6...\n",
      "Procesando muestra 7...\n",
      "Procesando muestra 8...\n",
      "Procesando muestra 9...\n",
      "Total graphs created: 10\n"
     ]
    }
   ],
   "source": [
    "# üìò Notebook: 02_model.ipynb\n",
    "# Construcci√≥n del dataset para GNN y entrenamiento de modelo\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import pandas as pd\n",
    "from matminer.datasets import load_dataset\n",
    "from pymatgen.analysis.graphs import StructureGraph\n",
    "from pymatgen.analysis.local_env import MinimumDistanceNN\n",
    "import numpy as np\n",
    "\n",
    "# Cargar dataset\n",
    "df = load_dataset(\"matbench_mp_e_form\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "\n",
    "\n",
    "# Tomar un subconjunto peque√±o para pruebas r√°pidas\n",
    "df_small = df.sample(10, random_state=42).reset_index(drop=True)\n",
    "# Lista para almacenar objetos Data de PyTorch Geometric\n",
    "data_list = []\n",
    "\n",
    "for i, row in df_small.iterrows():\n",
    "    print(f\"Procesando muestra {i}...\")\n",
    "\n",
    "    try:\n",
    "        structure = row['structure']\n",
    "        energy = row['e_form']\n",
    "\n",
    "        # Crear grafo con CrystalNN\n",
    "        sg = StructureGraph.with_local_env_strategy(structure, MinimumDistanceNN())\n",
    "        edges = sg.graph.edges()\n",
    "\n",
    "        # Nodos: n√∫mero at√≥mico de cada √°tomo\n",
    "        z = torch.tensor([site.specie.Z for site in structure.sites], dtype=torch.float)\n",
    "\n",
    "        # Aristas: pares de nodos conectados\n",
    "        edge_index = torch.tensor(list(edges), dtype=torch.long).t().contiguous()\n",
    "\n",
    "        # Crear objeto Data para PyTorch Geometric\n",
    "        data = Data(x=z.view(-1, 1), edge_index=edge_index, y=torch.tensor([energy], dtype=torch.float))\n",
    "        data_list.append(data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in sample {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Total graphs created: {len(data_list)}\")\n",
    "\n",
    "# Guardar data_list para usarlo en el entrenamiento (opcional)\n",
    "torch.save(data_list, \"data/gnn_graphs.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ed3bca-ba2e-4352-811d-b374dadc22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "file_path = \"data/gnn_graphs.pt\"\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    print(\"‚úÖ ¬°Archivo encontrado! ‚úÖ\")\n",
    "    data_list = torch.load(file_path)\n",
    "    print(f\"üì¶ N√∫mero de estructuras guardadas: {len(data_list)}\")\n",
    "else:\n",
    "    print(\"‚ùå El archivo no fue encontrado. Verifica que la ruta y el guardado est√©n correctos.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c846f92-2871-4e02-bf0d-bf496eba09c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           structure    e_form\n",
      "0  [[0. 0. 0.] Pt, [1.40802527 1.40802527 1.40802...  1.995384\n",
      "1  [[0. 0. 0.] Cd, [-3.88999977 -3.88999977 -3.88...  2.103048\n"
     ]
    }
   ],
   "source": [
    "from matminer.datasets import load_dataset\n",
    "\n",
    "# Cargar solo los primeros 2 registros\n",
    "df = load_dataset(\"matbench_mp_e_form\")[:2]  # <- MUY IMPORTANTE\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa1a4d9-16be-4cf6-9271-02825923726a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>structure</th>\n",
       "      <th>e_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0. 0. 0.] Cd, [-3.88999977 -3.88999977 -3.88...</td>\n",
       "      <td>2.103048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0. 0. 0.] Pt, [1.40802527 1.40802527 1.40802...</td>\n",
       "      <td>1.995384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           structure    e_form\n",
       "0  [[0. 0. 0.] Cd, [-3.88999977 -3.88999977 -3.88...  2.103048\n",
       "1  [[0. 0. 0.] Pt, [1.40802527 1.40802527 1.40802...  1.995384"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = df.sample(2, random_state=42).reset_index(drop=True)\n",
    "df_small.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ab8be9-5b52-42b5-b208-155d66407a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Grafo 0 procesado.\n",
      "‚úì Grafo 1 procesado.\n"
     ]
    }
   ],
   "source": [
    "from pymatgen.analysis.graphs import StructureGraph\n",
    "from pymatgen.analysis.local_env import MinimumDistanceNN\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "\n",
    "# Lista para guardar los objetos tipo Data\n",
    "data_list = []\n",
    "\n",
    "for i, row in df_small.iterrows():\n",
    "    try:\n",
    "        structure = row['structure']\n",
    "        energy = row['e_form']\n",
    "\n",
    "        # Grafo de la estructura con vecinos locales\n",
    "        sg = StructureGraph.with_local_env_strategy(structure, MinimumDistanceNN())\n",
    "        edges = sg.graph.edges()\n",
    "\n",
    "        # Nodo = n√∫mero at√≥mico\n",
    "        z = torch.tensor([site.specie.Z for site in structure.sites], dtype=torch.float)\n",
    "\n",
    "        # Aristas: nodos conectados\n",
    "        edge_index = torch.tensor(list(edges), dtype=torch.long).t().contiguous()\n",
    "\n",
    "        # Objeto tipo Data\n",
    "        data = Data(x=z.view(-1, 1), edge_index=edge_index, y=torch.tensor([energy], dtype=torch.float))\n",
    "        data_list.append(data)\n",
    "\n",
    "        print(f\"‚úì Grafo {i} procesado.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error en el grafo {i}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aec9310e-6f56-4eb5-b52d-9805db852196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo guardado exitosamente.\n",
      "üìÅ Archivo encontrado: data/gnn_graphs.pt\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torch_geometric.data.data.DataEdgeAttr was not an allowed global by default. Please use `torch.serialization.add_safe_globals([torch_geometric.data.data.DataEdgeAttr])` or the `torch.serialization.safe_globals([torch_geometric.data.data.DataEdgeAttr])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(file_path):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìÅ Archivo encontrado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     graphs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müìä N√∫mero de grafos guardados: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(graphs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\DATA_SCIENTIST\\DataScienceProjects\\material-discovery-gnn\\.venv-safe\\lib\\site-packages\\torch\\serialization.py:1524\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1516\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1517\u001b[0m                     opened_zipfile,\n\u001b[0;32m   1518\u001b[0m                     map_location,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1521\u001b[0m                     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1522\u001b[0m                 )\n\u001b[0;32m   1523\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1524\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[0;32m   1526\u001b[0m             opened_zipfile,\n\u001b[0;32m   1527\u001b[0m             map_location,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args,\n\u001b[0;32m   1531\u001b[0m         )\n\u001b[0;32m   1532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL torch_geometric.data.data.DataEdgeAttr was not an allowed global by default. Please use `torch.serialization.add_safe_globals([torch_geometric.data.data.DataEdgeAttr])` or the `torch.serialization.safe_globals([torch_geometric.data.data.DataEdgeAttr])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Ruta donde se guardar√° el archivo\n",
    "file_path = \"data/gnn_graphs.pt\"\n",
    "\n",
    "# Aseg√∫rate de que la carpeta 'data/' exista\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Guardar el archivo\n",
    "torch.save(data_list, file_path)\n",
    "print(\"‚úÖ Archivo guardado exitosamente.\")\n",
    "\n",
    "# Verificar\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"üìÅ Archivo encontrado: {file_path}\")\n",
    "    graphs = torch.load(file_path)\n",
    "    print(f\"üìä N√∫mero de grafos guardados: {len(graphs)}\")\n",
    "else:\n",
    "    print(\"‚ùå No se encontr√≥ el archivo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df5af47b-a1da-4ba7-860e-3c66f3ec23f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ PyTorch versi√≥n detectada: 2.7.1+cpu\n",
      "‚ùå Error al registrar clase `Data`: '<' not supported between instances of 'str' and 'int'\n",
      "üìä N√∫mero de grafos cargados: 2\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# Verificar versi√≥n de PyTorch\n",
    "torch_version = torch.__version__\n",
    "major_minor = tuple(map(int, re.match(r\"(\\d+)\\.(\\d+)\", torch_version).groups()))\n",
    "print(f\"üì¶ PyTorch versi√≥n detectada: {torch_version}\")\n",
    "\n",
    "# Ruta al archivo .pt\n",
    "file_path = \"data/gnn_graphs.pt\"\n",
    "\n",
    "# Registrar el paquete si PyTorch >= 2.6\n",
    "if major_minor >= (2, 6):\n",
    "    try:\n",
    "        torch.serialization.register_package(\n",
    "            \"torch_geometric.data.data\",     # Nombre del paquete\n",
    "            {\"Data\": Data},                  # Clases seguras\n",
    "            lambda s: eval(s)                # ‚ö†Ô∏è Deserializador inseguro (usa solo si el archivo es confiable)\n",
    "        )\n",
    "        print(\"üîê Registro de clase `Data` exitoso con `register_package`\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al registrar clase `Data`: {e}\")\n",
    "\n",
    "# Cargar el archivo\n",
    "try:\n",
    "    graphs = torch.load(file_path, weights_only=False)\n",
    "    print(f\"üìä N√∫mero de grafos cargados: {len(graphs)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al cargar el archivo `.pt`: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "234d1595-9d1a-4d82-a6f3-8673153cc4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Cantidad de grafos: 2\n",
      "Data(x=[2, 1], edge_index=[2, 4], y=[1])\n"
     ]
    }
   ],
   "source": [
    "# Mostrar tipo de dato y cantidad de grafos\n",
    "print(type(graphs))\n",
    "print(f\"Cantidad de grafos: {len(graphs)}\")\n",
    "\n",
    "# Ver el primer grafo\n",
    "print(graphs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3b2a243-6bef-4291-8daf-da3f200e6c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[2, 1], edge_index=[2, 4], y=[1])\n"
     ]
    }
   ],
   "source": [
    "# Ver informaci√≥n b√°sica del primer grafo\n",
    "graph = graphs[0]\n",
    "print(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6b95da1-3286-49f6-a125-7ad66d16b4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'y', 'edge_index']\n",
      "Nodos: 2\n",
      "Aristas: 4\n"
     ]
    }
   ],
   "source": [
    "# Listar atributos disponibles\n",
    "print(graph.keys())\n",
    "\n",
    "# Ver el n√∫mero de nodos y aristas\n",
    "print(f\"Nodos: {graph.num_nodes}\")\n",
    "print(f\"Aristas: {graph.num_edges}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed6b7821-da0f-40e1-b67f-9b061edcade4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convertir a objeto NetworkX\n",
    "nx_graph = to_networkx(graph)\n",
    "\n",
    "# Dibujar\n",
    "plt.figure(figsize=(5, 5))\n",
    "nx.draw(nx_graph, with_labels=True, node_color='lightblue', edge_color='gray')\n",
    "plt.title(\"Primer grafo cargado\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7d5a9a0-e05d-4fed-aa3a-9a8e38d4ebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ingna\\AppData\\Local\\Temp\\ipykernel_1344\\81861731.py:25: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Im√°genes guardadas en la carpeta 'images/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# Cu√°ntos grafos quieres visualizar (puedes cambiarlo)\n",
    "num_to_plot = 3\n",
    "\n",
    "for i in range(min(num_to_plot, len(graphs))):\n",
    "    graph = graphs[i]\n",
    "    G = to_networkx(graph)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    nx.draw(G, \n",
    "            with_labels=True,\n",
    "            node_color='skyblue',\n",
    "            edge_color='gray',\n",
    "            node_size=500,\n",
    "            font_size=10)\n",
    "    \n",
    "    plt.title(f\"Grafo {i}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"images/graph_{i}.png\")\n",
    "    plt.close()\n",
    "\n",
    "print(f\"‚úÖ Im√°genes guardadas en la carpeta 'images/'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b79efe-a4b0-4030-9cf2-2624bdd7da9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GNN Safe)",
   "language": "python",
   "name": "gnn-safe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
